{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591ff253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4242af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE = 42 \n",
    "TT_RATIO = 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cdd3e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sexist</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MENTION3481 i didn't even know random was an o...</td>\n",
       "      <td>False</td>\n",
       "      <td>mention3481 didnt even know random option</td>\n",
       "      <td>mention3481 didnt even know random option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bottom two should've gone!  #mkr</td>\n",
       "      <td>False</td>\n",
       "      <td>bottom two shouldv gone mkr</td>\n",
       "      <td>bottom two shouldve go mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MENTION3111 MENTION3424 ladyboner deserves so ...</td>\n",
       "      <td>False</td>\n",
       "      <td>mention3111 mention3424 ladybon deserv much cr...</td>\n",
       "      <td>mention3111 mention3424 ladyboner deserves muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She shall now be known as Sourpuss #MKR #KatAn...</td>\n",
       "      <td>False</td>\n",
       "      <td>shall known sourpuss mkr katandr failedfoodi</td>\n",
       "      <td>shall know sourpuss mkr katandre failedfoodies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tarah W threw a bunch of women under the bus s...</td>\n",
       "      <td>False</td>\n",
       "      <td>tarah w threw bunch women bu could get wadhwa ...</td>\n",
       "      <td>tarah w threw bunch woman bus could get wadhwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>this reminds me of the MENTION3079 situation; ...</td>\n",
       "      <td>False</td>\n",
       "      <td>remind mention3079 situat sorri actual dont ca...</td>\n",
       "      <td>reminds mention3079 situation sorry actually d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>#mkr I love Annie and loyld there like a real ...</td>\n",
       "      <td>False</td>\n",
       "      <td>mkr love anni loyld like real life disney coup...</td>\n",
       "      <td>mkr love annie loyld like real life disney cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>No u. http://t.co/zOr0eWahSS</td>\n",
       "      <td>False</td>\n",
       "      <td>u httptcozor0ewahss</td>\n",
       "      <td>u httptcozor0ewahss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>#mkr the way kat looks at Annie is like she's ...</td>\n",
       "      <td>False</td>\n",
       "      <td>mkr way kat look anni like she stear soul creepi</td>\n",
       "      <td>mkr way kat look annie like shes stearing soul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>#mkr omg the kiss stains on the \"dirty\" mirror...</td>\n",
       "      <td>False</td>\n",
       "      <td>mkr omg kiss stain dirti mirror sooo tacki oh god</td>\n",
       "      <td>mkr omg kiss stain dirty mirror sooo tacky oh god</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13345 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sexist  \\\n",
       "0      MENTION3481 i didn't even know random was an o...   False   \n",
       "1                       Bottom two should've gone!  #mkr   False   \n",
       "2      MENTION3111 MENTION3424 ladyboner deserves so ...   False   \n",
       "3      She shall now be known as Sourpuss #MKR #KatAn...   False   \n",
       "4      Tarah W threw a bunch of women under the bus s...   False   \n",
       "...                                                  ...     ...   \n",
       "13340  this reminds me of the MENTION3079 situation; ...   False   \n",
       "13341  #mkr I love Annie and loyld there like a real ...   False   \n",
       "13342                       No u. http://t.co/zOr0eWahSS   False   \n",
       "13343  #mkr the way kat looks at Annie is like she's ...   False   \n",
       "13344  #mkr omg the kiss stains on the \"dirty\" mirror...   False   \n",
       "\n",
       "                                          processed_text  \\\n",
       "0              mention3481 didnt even know random option   \n",
       "1                            bottom two shouldv gone mkr   \n",
       "2      mention3111 mention3424 ladybon deserv much cr...   \n",
       "3           shall known sourpuss mkr katandr failedfoodi   \n",
       "4      tarah w threw bunch women bu could get wadhwa ...   \n",
       "...                                                  ...   \n",
       "13340  remind mention3079 situat sorri actual dont ca...   \n",
       "13341  mkr love anni loyld like real life disney coup...   \n",
       "13342                                u httptcozor0ewahss   \n",
       "13343   mkr way kat look anni like she stear soul creepi   \n",
       "13344  mkr omg kiss stain dirti mirror sooo tacki oh god   \n",
       "\n",
       "                                                lem_text  \n",
       "0              mention3481 didnt even know random option  \n",
       "1                             bottom two shouldve go mkr  \n",
       "2      mention3111 mention3424 ladyboner deserves muc...  \n",
       "3         shall know sourpuss mkr katandre failedfoodies  \n",
       "4      tarah w threw bunch woman bus could get wadhwa...  \n",
       "...                                                  ...  \n",
       "13340  reminds mention3079 situation sorry actually d...  \n",
       "13341  mkr love annie loyld like real life disney cou...  \n",
       "13342                                u httptcozor0ewahss  \n",
       "13343  mkr way kat look annie like shes stearing soul...  \n",
       "13344  mkr omg kiss stain dirty mirror sooo tacky oh god  \n",
       "\n",
       "[13345 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"processed_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01dd54c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mm527x/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Load the stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to preprocess the text and generate n-grams\n",
    "def preprocess_text(text):\n",
    "    # Normalize the text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Generate n-grams\n",
    "    ngrams_list = list(ngrams(tokens, 4))\n",
    "    # Join the n-grams back into a string\n",
    "    text = [' '.join(gram) for gram in ngrams_list]\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column of your DataFrame\n",
    "df['ngram_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Save the processed dataset\n",
    "df.to_csv('processed_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124f86b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mm527x/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Load the stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to preprocess the text and generate n-grams\n",
    "def preprocess_text(text):\n",
    "    # Normalize the text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Generate n-grams\n",
    "    ngrams_list_2 = list(ngrams(tokens, 2))\n",
    "    ngrams_list_4 = list(ngrams(tokens, 4))\n",
    "    # Join the n-grams back into strings\n",
    "    ngram_text_2 = [' '.join(gram) for gram in ngrams_list_2]\n",
    "    ngram_text_4 = [' '.join(gram) for gram in ngrams_list_4]\n",
    "    return ngram_text_2, ngram_text_4\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column of your DataFrame\n",
    "df[['ngram_text_2', 'ngram_text_4']] = df['text'].apply(preprocess_text).apply(pd.Series)\n",
    "\n",
    "# Save the processed dataset\n",
    "df.to_csv('processed_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8a7e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=pd.read_csv(\"processed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da53a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['sexist'] = processed_df['sexist'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5fdcaaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sexist</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_text_2</th>\n",
       "      <th>ngram_text_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MENTION3481 i didn't even know random was an o...</td>\n",
       "      <td>0</td>\n",
       "      <td>mention3481 didnt even know random option</td>\n",
       "      <td>mention3481 didnt even know random option</td>\n",
       "      <td>['mention3481 didnt even know', 'didnt even kn...</td>\n",
       "      <td>['mention3481 didnt', 'didnt even', 'even know...</td>\n",
       "      <td>['mention3481 didnt even know', 'didnt even kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bottom two should've gone!  #mkr</td>\n",
       "      <td>0</td>\n",
       "      <td>bottom two shouldv gone mkr</td>\n",
       "      <td>bottom two shouldve go mkr</td>\n",
       "      <td>['bottom two shouldve gone', 'two shouldve gon...</td>\n",
       "      <td>['bottom two', 'two shouldve', 'shouldve gone'...</td>\n",
       "      <td>['bottom two shouldve gone', 'two shouldve gon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MENTION3111 MENTION3424 ladyboner deserves so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mention3111 mention3424 ladybon deserv much cr...</td>\n",
       "      <td>mention3111 mention3424 ladyboner deserves muc...</td>\n",
       "      <td>['mention3111 mention3424 ladyboner deserves',...</td>\n",
       "      <td>['mention3111 mention3424', 'mention3424 ladyb...</td>\n",
       "      <td>['mention3111 mention3424 ladyboner deserves',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She shall now be known as Sourpuss #MKR #KatAn...</td>\n",
       "      <td>0</td>\n",
       "      <td>shall known sourpuss mkr katandr failedfoodi</td>\n",
       "      <td>shall know sourpuss mkr katandre failedfoodies</td>\n",
       "      <td>['shall known sourpuss mkr', 'known sourpuss m...</td>\n",
       "      <td>['shall known', 'known sourpuss', 'sourpuss mk...</td>\n",
       "      <td>['shall known sourpuss mkr', 'known sourpuss m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tarah W threw a bunch of women under the bus s...</td>\n",
       "      <td>0</td>\n",
       "      <td>tarah w threw bunch women bu could get wadhwa ...</td>\n",
       "      <td>tarah w threw bunch woman bus could get wadhwa...</td>\n",
       "      <td>['tarah w threw bunch', 'w threw bunch woman',...</td>\n",
       "      <td>['tarah w', 'w threw', 'threw bunch', 'bunch w...</td>\n",
       "      <td>['tarah w threw bunch', 'w threw bunch woman',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>this reminds me of the MENTION3079 situation; ...</td>\n",
       "      <td>0</td>\n",
       "      <td>remind mention3079 situat sorri actual dont ca...</td>\n",
       "      <td>reminds mention3079 situation sorry actually d...</td>\n",
       "      <td>['reminds mention3079 situation sorry', 'menti...</td>\n",
       "      <td>['reminds mention3079', 'mention3079 situation...</td>\n",
       "      <td>['reminds mention3079 situation sorry', 'menti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>#mkr I love Annie and loyld there like a real ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mkr love anni loyld like real life disney coup...</td>\n",
       "      <td>mkr love annie loyld like real life disney cou...</td>\n",
       "      <td>['mkr love annie loyld', 'love annie loyld lik...</td>\n",
       "      <td>['mkr love', 'love annie', 'annie loyld', 'loy...</td>\n",
       "      <td>['mkr love annie loyld', 'love annie loyld lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>No u. http://t.co/zOr0eWahSS</td>\n",
       "      <td>0</td>\n",
       "      <td>u httptcozor0ewahss</td>\n",
       "      <td>u httptcozor0ewahss</td>\n",
       "      <td>[]</td>\n",
       "      <td>['u httptcozor0ewahss']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>#mkr the way kat looks at Annie is like she's ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mkr way kat look anni like she stear soul creepi</td>\n",
       "      <td>mkr way kat look annie like shes stearing soul...</td>\n",
       "      <td>['mkr way kat look', 'way kat look annie', 'ka...</td>\n",
       "      <td>['mkr way', 'way kat', 'kat look', 'look annie...</td>\n",
       "      <td>['mkr way kat look', 'way kat look annie', 'ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>#mkr omg the kiss stains on the \"dirty\" mirror...</td>\n",
       "      <td>0</td>\n",
       "      <td>mkr omg kiss stain dirti mirror sooo tacki oh god</td>\n",
       "      <td>mkr omg kiss stain dirty mirror sooo tacky oh god</td>\n",
       "      <td>['mkr omg kiss stain', 'omg kiss stain dirty',...</td>\n",
       "      <td>['mkr omg', 'omg kiss', 'kiss stain', 'stain d...</td>\n",
       "      <td>['mkr omg kiss stain', 'omg kiss stain dirty',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13345 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sexist  \\\n",
       "0      MENTION3481 i didn't even know random was an o...       0   \n",
       "1                       Bottom two should've gone!  #mkr       0   \n",
       "2      MENTION3111 MENTION3424 ladyboner deserves so ...       0   \n",
       "3      She shall now be known as Sourpuss #MKR #KatAn...       0   \n",
       "4      Tarah W threw a bunch of women under the bus s...       0   \n",
       "...                                                  ...     ...   \n",
       "13340  this reminds me of the MENTION3079 situation; ...       0   \n",
       "13341  #mkr I love Annie and loyld there like a real ...       0   \n",
       "13342                       No u. http://t.co/zOr0eWahSS       0   \n",
       "13343  #mkr the way kat looks at Annie is like she's ...       0   \n",
       "13344  #mkr omg the kiss stains on the \"dirty\" mirror...       0   \n",
       "\n",
       "                                          processed_text  \\\n",
       "0              mention3481 didnt even know random option   \n",
       "1                            bottom two shouldv gone mkr   \n",
       "2      mention3111 mention3424 ladybon deserv much cr...   \n",
       "3           shall known sourpuss mkr katandr failedfoodi   \n",
       "4      tarah w threw bunch women bu could get wadhwa ...   \n",
       "...                                                  ...   \n",
       "13340  remind mention3079 situat sorri actual dont ca...   \n",
       "13341  mkr love anni loyld like real life disney coup...   \n",
       "13342                                u httptcozor0ewahss   \n",
       "13343   mkr way kat look anni like she stear soul creepi   \n",
       "13344  mkr omg kiss stain dirti mirror sooo tacki oh god   \n",
       "\n",
       "                                                lem_text  \\\n",
       "0              mention3481 didnt even know random option   \n",
       "1                             bottom two shouldve go mkr   \n",
       "2      mention3111 mention3424 ladyboner deserves muc...   \n",
       "3         shall know sourpuss mkr katandre failedfoodies   \n",
       "4      tarah w threw bunch woman bus could get wadhwa...   \n",
       "...                                                  ...   \n",
       "13340  reminds mention3079 situation sorry actually d...   \n",
       "13341  mkr love annie loyld like real life disney cou...   \n",
       "13342                                u httptcozor0ewahss   \n",
       "13343  mkr way kat look annie like shes stearing soul...   \n",
       "13344  mkr omg kiss stain dirty mirror sooo tacky oh god   \n",
       "\n",
       "                                              ngram_text  \\\n",
       "0      ['mention3481 didnt even know', 'didnt even kn...   \n",
       "1      ['bottom two shouldve gone', 'two shouldve gon...   \n",
       "2      ['mention3111 mention3424 ladyboner deserves',...   \n",
       "3      ['shall known sourpuss mkr', 'known sourpuss m...   \n",
       "4      ['tarah w threw bunch', 'w threw bunch woman',...   \n",
       "...                                                  ...   \n",
       "13340  ['reminds mention3079 situation sorry', 'menti...   \n",
       "13341  ['mkr love annie loyld', 'love annie loyld lik...   \n",
       "13342                                                 []   \n",
       "13343  ['mkr way kat look', 'way kat look annie', 'ka...   \n",
       "13344  ['mkr omg kiss stain', 'omg kiss stain dirty',...   \n",
       "\n",
       "                                            ngram_text_2  \\\n",
       "0      ['mention3481 didnt', 'didnt even', 'even know...   \n",
       "1      ['bottom two', 'two shouldve', 'shouldve gone'...   \n",
       "2      ['mention3111 mention3424', 'mention3424 ladyb...   \n",
       "3      ['shall known', 'known sourpuss', 'sourpuss mk...   \n",
       "4      ['tarah w', 'w threw', 'threw bunch', 'bunch w...   \n",
       "...                                                  ...   \n",
       "13340  ['reminds mention3079', 'mention3079 situation...   \n",
       "13341  ['mkr love', 'love annie', 'annie loyld', 'loy...   \n",
       "13342                            ['u httptcozor0ewahss']   \n",
       "13343  ['mkr way', 'way kat', 'kat look', 'look annie...   \n",
       "13344  ['mkr omg', 'omg kiss', 'kiss stain', 'stain d...   \n",
       "\n",
       "                                            ngram_text_4  \n",
       "0      ['mention3481 didnt even know', 'didnt even kn...  \n",
       "1      ['bottom two shouldve gone', 'two shouldve gon...  \n",
       "2      ['mention3111 mention3424 ladyboner deserves',...  \n",
       "3      ['shall known sourpuss mkr', 'known sourpuss m...  \n",
       "4      ['tarah w threw bunch', 'w threw bunch woman',...  \n",
       "...                                                  ...  \n",
       "13340  ['reminds mention3079 situation sorry', 'menti...  \n",
       "13341  ['mkr love annie loyld', 'love annie loyld lik...  \n",
       "13342                                                 []  \n",
       "13343  ['mkr way kat look', 'way kat look annie', 'ka...  \n",
       "13344  ['mkr omg kiss stain', 'omg kiss stain dirty',...  \n",
       "\n",
       "[13345 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e699344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11538\n",
      "1     1807\n",
      "Name: sexist, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(processed_df['sexist'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d096c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram2=processed_df[['ngram_text_2','sexist']]\n",
    "df_ngram4=processed_df[['ngram_text_4','sexist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a404f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_text_2</th>\n",
       "      <th>sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['mention3481 didnt', 'didnt even', 'even know...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bottom two', 'two shouldve', 'shouldve gone'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['mention3111 mention3424', 'mention3424 ladyb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['shall known', 'known sourpuss', 'sourpuss mk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['tarah w', 'w threw', 'threw bunch', 'bunch w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>['reminds mention3079', 'mention3079 situation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>['mkr love', 'love annie', 'annie loyld', 'loy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>['u httptcozor0ewahss']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>['mkr way', 'way kat', 'kat look', 'look annie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>['mkr omg', 'omg kiss', 'kiss stain', 'stain d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13345 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ngram_text_2  sexist\n",
       "0      ['mention3481 didnt', 'didnt even', 'even know...       0\n",
       "1      ['bottom two', 'two shouldve', 'shouldve gone'...       0\n",
       "2      ['mention3111 mention3424', 'mention3424 ladyb...       0\n",
       "3      ['shall known', 'known sourpuss', 'sourpuss mk...       0\n",
       "4      ['tarah w', 'w threw', 'threw bunch', 'bunch w...       0\n",
       "...                                                  ...     ...\n",
       "13340  ['reminds mention3079', 'mention3079 situation...       0\n",
       "13341  ['mkr love', 'love annie', 'annie loyld', 'loy...       0\n",
       "13342                            ['u httptcozor0ewahss']       0\n",
       "13343  ['mkr way', 'way kat', 'kat look', 'look annie...       0\n",
       "13344  ['mkr omg', 'omg kiss', 'kiss stain', 'stain d...       0\n",
       "\n",
       "[13345 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4524dc75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_text_4</th>\n",
       "      <th>sexist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['mention3481 didnt even know', 'didnt even kn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bottom two shouldve gone', 'two shouldve gon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['mention3111 mention3424 ladyboner deserves',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['shall known sourpuss mkr', 'known sourpuss m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['tarah w threw bunch', 'w threw bunch woman',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>['reminds mention3079 situation sorry', 'menti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>['mkr love annie loyld', 'love annie loyld lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>['mkr way kat look', 'way kat look annie', 'ka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>['mkr omg kiss stain', 'omg kiss stain dirty',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13345 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ngram_text_4  sexist\n",
       "0      ['mention3481 didnt even know', 'didnt even kn...       0\n",
       "1      ['bottom two shouldve gone', 'two shouldve gon...       0\n",
       "2      ['mention3111 mention3424 ladyboner deserves',...       0\n",
       "3      ['shall known sourpuss mkr', 'known sourpuss m...       0\n",
       "4      ['tarah w threw bunch', 'w threw bunch woman',...       0\n",
       "...                                                  ...     ...\n",
       "13340  ['reminds mention3079 situation sorry', 'menti...       0\n",
       "13341  ['mkr love annie loyld', 'love annie loyld lik...       0\n",
       "13342                                                 []       0\n",
       "13343  ['mkr way kat look', 'way kat look annie', 'ka...       0\n",
       "13344  ['mkr omg kiss stain', 'omg kiss stain dirty',...       0\n",
       "\n",
       "[13345 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3122d5",
   "metadata": {},
   "source": [
    "# ngram2 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7866c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (13345, 2)\n",
      "Testing set shape: (13345, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "ngram2_train_df, ngram2_test_df = train_test_split(df_ngram2, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shape of the resulting DataFrames\n",
    "print(f\"Training set shape: {df_ngram2.shape}\")\n",
    "print(f\"Testing set shape: {df_ngram2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f01e9f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8834\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.93      2884\n",
      "           1       0.62      0.36      0.45       453\n",
      "\n",
      "    accuracy                           0.88      3337\n",
      "   macro avg       0.76      0.66      0.69      3337\n",
      "weighted avg       0.87      0.88      0.87      3337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Get the training and testing texts and labels\n",
    "ngram2_train_texts = ngram2_train_df['ngram_text_2']\n",
    "ngram2_train_labels = ngram2_train_df['sexist']\n",
    "ngram2_test_texts = ngram2_test_df['ngram_text_2']\n",
    "ngram2_test_labels = ngram2_test_df['sexist']\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_features = vectorizer.fit_transform(ngram2_train_texts)  # Transform the training texts\n",
    "\n",
    "# Transform the testing texts using the same vectorizer\n",
    "test_features = vectorizer.transform(ngram2_test_texts)\n",
    "\n",
    "# Create an SVM classifier\n",
    "classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(train_features, ngram2_train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(ngram2_test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(ngram2_test_labels, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1c91416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      2884\n",
      "           1       0.65      0.57      0.61       453\n",
      "\n",
      "    accuracy                           0.90      3337\n",
      "   macro avg       0.79      0.76      0.78      3337\n",
      "weighted avg       0.90      0.90      0.90      3337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train = ngram2_train_df['ngram_text_2']\n",
    "y_train = ngram2_train_df['sexist']\n",
    "X_test = ngram2_test_df['ngram_text_2']\n",
    "y_test = ngram2_test_df['sexist']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_table = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "70d514a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9008\n",
      "Precision: 0.6459\n",
      "Recall: 0.5960\n",
      "F1-Score: 0.6200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      2884\n",
      "           1       0.65      0.60      0.62       453\n",
      "\n",
      "    accuracy                           0.90      3337\n",
      "   macro avg       0.79      0.77      0.78      3337\n",
      "weighted avg       0.90      0.90      0.90      3337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27939ddd",
   "metadata": {},
   "source": [
    "# ngram4 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a165ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (13345, 2)\n",
      "Testing set shape: (13345, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "ngram4_train_df, ngram4_test_df = train_test_split(df_ngram4, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shape of the resulting DataFrames\n",
    "print(f\"Training set shape: {df_ngram4.shape}\")\n",
    "print(f\"Testing set shape: {df_ngram4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70172b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8810\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      2884\n",
      "           1       0.63      0.30      0.41       453\n",
      "\n",
      "    accuracy                           0.88      3337\n",
      "   macro avg       0.76      0.64      0.67      3337\n",
      "weighted avg       0.86      0.88      0.86      3337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Get the training and testing texts and labels\n",
    "ngram4_train_texts = ngram4_train_df['ngram_text_4']\n",
    "ngram4_train_labels = ngram4_train_df['sexist']\n",
    "ngram4_test_texts = ngram4_test_df['ngram_text_4']\n",
    "ngram4_test_labels = ngram4_test_df['sexist']\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_features = vectorizer.fit_transform(ngram4_train_texts)  # Transform the training texts\n",
    "\n",
    "# Transform the testing texts using the same vectorizer\n",
    "test_features = vectorizer.transform(ngram4_test_texts)\n",
    "\n",
    "# Create an SVM classifier\n",
    "classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(train_features, ngram4_train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(ngram4_test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(ngram4_test_labels, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af459cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      2884\n",
      "           1       0.65      0.51      0.57       453\n",
      "\n",
      "    accuracy                           0.90      3337\n",
      "   macro avg       0.79      0.73      0.76      3337\n",
      "weighted avg       0.89      0.90      0.89      3337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train = ngram4_train_df['ngram_text_4']\n",
    "y_train = ngram4_train_df['sexist']\n",
    "X_test = ngram4_test_df['ngram_text_4']\n",
    "y_test = ngram4_test_df['sexist']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_table = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "547353c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'gamma': 0, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      2884\n",
      "           1       0.65      0.22      0.33       453\n",
      "\n",
      "    accuracy                           0.88      3337\n",
      "   macro avg       0.77      0.60      0.63      3337\n",
      "weighted avg       0.86      0.88      0.85      3337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train = ngram4_train_df['ngram_text_4']\n",
    "y_train = ngram4_train_df['sexist']\n",
    "X_test = ngram4_test_df['ngram_text_4']\n",
    "y_test = ngram4_test_df['sexist']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='precision', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best classifier and its predictions on the test data\n",
    "best_classifier = grid_search.best_estimator_\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_table = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best hyperparameters and the classification report\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588f5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
